{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e1cf01-6686-4fa2-b442-2821cbd5849e",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed008256-775b-4cb0-b0a0-fe3a5a1c72ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e396c91b-2b19-41e8-9523-00caa17697a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53900f1d-7096-46f2-8d4f-e19feaa49537",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'FIRSTNAME',\n",
       "  'score': 0.44788054,\n",
       "  'word': 'Hicham,',\n",
       "  'start': 12,\n",
       "  'end': 19},\n",
       " {'entity_group': 'CREDITCARDNUMBER',\n",
       "  'score': 0.3592835,\n",
       "  'word': '4442223314488.',\n",
       "  'start': 89,\n",
       "  'end': 103}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"./taln_pii_cs_models_local/taln_pii_cs_model\"\n",
    "\n",
    "data = \"Mon nom est Hicham, et pour l'anniversaire de 50ans et je vais payer avec une carte visa 4442223314488.\"\n",
    "model = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"first\" #\"simple\"\n",
    ")\n",
    "preds = model(data)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f77f92-ebd8-4939-a535-1dc00066a921",
   "metadata": {},
   "source": [
    "#### Prepare Model Artifact\n",
    "Instantiate a HuggingFacePipelineModel() object with HuggingFace pipelines. All the pipelines related files are saved under the artifact_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21368935-3fa3-4637-b617-ed1fef1ff0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                  ?, ?it/s]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "algorithm: TokenClassificationPipeline\n",
       "artifact_dir:\n",
       "  /home/datascience/taln_pii_cs_models:\n",
       "  - - sentencepiece.bpe.model\n",
       "    - added_tokens.json\n",
       "    - pytorch_model.bin\n",
       "    - score.py\n",
       "    - test_json_output.json\n",
       "    - .model-ignore\n",
       "    - tokenizer.json\n",
       "    - model.safetensors\n",
       "    - runtime.yaml\n",
       "    - special_tokens_map.json\n",
       "    - config.json\n",
       "    - tokenizer_config.json\n",
       "framework: transformers\n",
       "model_deployment_id: null\n",
       "model_id: null"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.model import HuggingFacePipelineModel\n",
    "\n",
    "\n",
    "import tempfile\n",
    "\n",
    "#import oci\n",
    "#signer = oci.auth.signers.get_resource_principals_signer()\n",
    "ads.set_auth(auth='resource_principal')\n",
    "\n",
    "# Prepare the model\n",
    "artifact_dir = \"./taln_pii_cs_models\"\n",
    "huggingface_pipeline_model = HuggingFacePipelineModel(model, artifact_dir=artifact_dir)\n",
    "huggingface_pipeline_model.prepare(\n",
    "  inference_conda_env=\"oci://taln_pii_cs_conda_envs@yz2wwgkgt8eh/conda_environments/gpu/PyTorch 2.1 for GPU on Python 3.9/1.0/pytorch21_p39_gpu_v1\",\n",
    "  inference_python_version=\"3.9\",\n",
    "  training_conda_env=\"oci://taln_pii_cs_conda_envs@yz2wwgkgt8eh/conda_environments/gpu/PyTorch 2.1 for GPU on Python 3.9/1.0/pytorch21_p39_gpu_v1\",\n",
    "  use_case_type=UseCaseType.OTHER,\n",
    "  force_overwrite=True,\n",
    "  )\n",
    "# You don't need to modify the score.py generated. The model can be loaded by the transformers.pipeline.\n",
    "# More info here - https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61715d79-9ff8-4ff9-a6ea-cad1bff3adf0",
   "metadata": {},
   "source": [
    "#### Manually correct score.py\n",
    "\n",
    "1- In the method load_model, add a correction that introduces an aggregation_strategy parameter for pipeline, specifically set to \"first\"\n",
    "comment out the original line:\n",
    "```\n",
    "        # model = pipeline(task, model = model_dir)\n",
    "```\n",
    "Add the new lines below the commented line:\n",
    "```\n",
    "        #hicham's fix to add ner aggregation_strategy\n",
    "        model = pipeline(task, model = model_dir, aggregation_strategy=\"first\")\n",
    "```\n",
    "2- In the method serialize_prediction, add a correction that fixes the error \"The inference result is not json parsable Object of type float32 is not JSON serializable\"\n",
    "```\n",
    "    \"\"\"\n",
    "    if isinstance(yhat, dict):\n",
    "        for key, value in yhat.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                yhat[key] = value.tolist()\n",
    "            elif str(type(value)).startswith(\"<class 'PIL.\"):\n",
    "                import PIL\n",
    "                yhat[key] = np.asarray(value).tolist() if isinstance(value, PIL.Image.Image) else value\n",
    "    \"\"\"\n",
    "    \n",
    "    #hicham's fix for the error \"The inference result is not json parsable Object of type float32 is not JSON serializable\" \n",
    "    if isinstance(yhat, dict):\n",
    "        for key, value in yhat.items():\n",
    "            if isinstance(value, np.float32):\n",
    "                yhat[key] = float(value)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3231f726-087d-4a13-aba9-c4ea22612fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencepiece.bpe.model', 'added_tokens.json', 'pytorch_model.bin', 'score.py', 'test_json_output.json', '.model-ignore', 'tokenizer.json', 'model.safetensors', 'runtime.yaml', 'special_tokens_map.json', 'config.json', 'tokenizer_config.json']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test key</th>\n",
       "      <th>Test name</th>\n",
       "      <th>Result</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>runtime_env_path</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>runtime_env_python</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>runtime_path_exist</td>\n",
       "      <td>Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>runtime_version</td>\n",
       "      <td>Check that field MODEL_ARTIFACT_VERSION is set to 3.0</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>runtime_yaml</td>\n",
       "      <td>Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>score_load_model</td>\n",
       "      <td>Check that load_model() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>score_predict</td>\n",
       "      <td>Check that predict() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>score_predict_arg</td>\n",
       "      <td>Check that all other arguments in predict() are optional and have default values</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>score_predict_data</td>\n",
       "      <td>Check that the only required argument for predict() is named \"data\"</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>score_py</td>\n",
       "      <td>Check that the file \"score.py\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>score_syntax</td>\n",
       "      <td>Check for Python syntax errors</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test key  \\\n",
       "0     runtime_env_path   \n",
       "1   runtime_env_python   \n",
       "2   runtime_path_exist   \n",
       "3      runtime_version   \n",
       "4         runtime_yaml   \n",
       "5     score_load_model   \n",
       "6        score_predict   \n",
       "7    score_predict_arg   \n",
       "8   score_predict_data   \n",
       "9             score_py   \n",
       "10        score_syntax   \n",
       "\n",
       "                                                                                                Test name  \\\n",
       "0                                             Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set   \n",
       "1           Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher   \n",
       "2                             Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.   \n",
       "3                                                   Check that field MODEL_ARTIFACT_VERSION is set to 3.0   \n",
       "4   Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory   \n",
       "5                                                                      Check that load_model() is defined   \n",
       "6                                                                         Check that predict() is defined   \n",
       "7                        Check that all other arguments in predict() are optional and have default values   \n",
       "8                                     Check that the only required argument for predict() is named \"data\"   \n",
       "9       Check that the file \"score.py\" exists and is in the top level directory of the artifact directory   \n",
       "10                                                                         Check for Python syntax errors   \n",
       "\n",
       "    Result Message  \n",
       "0   Passed          \n",
       "1   Passed          \n",
       "2   Passed          \n",
       "3   Passed          \n",
       "4   Passed          \n",
       "5   Passed          \n",
       "6   Passed          \n",
       "7   Passed          \n",
       "8   Passed          \n",
       "9   Passed          \n",
       "10  Passed          "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_pipeline_model.introspect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83676a-27f7-4eb8-801a-1fd547b827ca",
   "metadata": {},
   "source": [
    "##### Call model summary\n",
    "The .summary_status() method returns a Pandas dataframe that guides you through the entire workflow. It shows which methods are available to call and which ones arenâ€™t. Plus it outlines what each method does. If extra actions are required, it also shows those actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3f1e78-1b36-4576-b130-6dbb554aa022",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Available     Local tested .predict from score.py                               \n",
       "save()    Available     Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_pipeline_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e2fcff-2797-4e66-93fd-7c50e4e08058",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Verify the generated model artifacts \n",
    "without deploying the model to model catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7f19a39-6dd0-49a0-b661-46eb60151d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is successfully loaded.\n",
      "WARNING:py.warnings:/home/datascience/conda/pytorch21_p39_gpu_v1/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:393: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': [{'entity_group': 'FIRSTNAME',\n",
       "   'score': 0.4478805363178253,\n",
       "   'word': 'Hicham,',\n",
       "   'start': 12,\n",
       "   'end': 19},\n",
       "  {'entity_group': 'CREDITCARDNUMBER',\n",
       "   'score': 0.3592835068702698,\n",
       "   'word': '4442223314488.',\n",
       "   'start': 89,\n",
       "   'end': 103}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_pipeline_model.verify(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b75144-732b-4436-826a-96b676239672",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8330d8c1-bc94-4a96-b4c5-3ec94c1310d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is successfully loaded.\n",
      "['sentencepiece.bpe.model', 'added_tokens.json', 'pytorch_model.bin', 'score.py', 'test_json_output.json', '.model-ignore', 'tokenizer.json', 'model.safetensors', 'runtime.yaml', 'special_tokens_map.json', 'config.json', 'tokenizer_config.json']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Register the model\n",
    "\n",
    "model_id = huggingface_pipeline_model.save(display_name=\"TALN PII Case Study Model-pytorch8.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e93ce-8219-446f-b9ab-29e0f61b0d07",
   "metadata": {},
   "source": [
    "#### Deploy and Generate Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a00918c9-3692-41ef-b027-dfa5b9f25dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Deployment OCID: ocid1.datasciencemodeldeployment.oc1.ca-toronto-1.amaaaaaa3hvgr2qazlfu5f5vwmt7k7j5bp3bpn7la73tnvqrca36ibtcmhla\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating model deployment:   0%|          | [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://modeldeployment.ca-toronto-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.ca-toronto-1.amaaaaaa3hvgr2qazlfu5f5vwmt7k7j5bp3bpn7la73tnvqrca36ibtcmhla\n"
     ]
    }
   ],
   "source": [
    "# Deploy and create an endpoint for the huggingface_pipeline_model\n",
    "huggingface_pipeline_model.deploy(\n",
    "    display_name=\"TALN PII Case Study Model-deployment-pytorch8.0\", #HuggingFace Pipeline Model\n",
    "    deployment_log_group_id=\"ocid1.loggroup.oc1.ca-toronto-1.amaaaaaa3hvgr2qa4t42gdsnhm6ijpsfzhkizrzpp3cbfhvds2fnm2ejczaq\",\n",
    "    deployment_access_log_id=\"ocid1.log.oc1.ca-toronto-1.amaaaaaa3hvgr2qajbioaw6ru5o4hzt5q767rngzprsojfqemqvsoaa3cj6a\",\n",
    "    deployment_predict_log_id=\"ocid1.log.oc1.ca-toronto-1.amaaaaaa3hvgr2qajbioaw6ru5o4hzt5q767rngzprsojfqemqvsoaa3cj6a\",\n",
    "    # Shape config details mandatory for flexible shapes:\n",
    "    # deployment_instance_shape=\"VM.Standard.E4.Flex\",\n",
    "    # deployment_ocpus=<number>,\n",
    "    # deployment_memory_in_gbs=<number>,\n",
    ")\n",
    "print(f\"Endpoint: {huggingface_pipeline_model.model_deployment.url}\")\n",
    "# Output: \"Endpoint: https://modeldeployment.{region}.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.xxx.xxxxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390ee17-8d9b-46f1-a317-069251136f99",
   "metadata": {},
   "source": [
    "### Run Prediction against Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd2130f3-282f-498d-b7e6-4f23f4415239",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hicham, FIRSTNAME 0.4478805363178253 12 19\n",
      "4442223314488. CREDITCARDNUMBER 0.3592835068702698 89 103\n"
     ]
    }
   ],
   "source": [
    "# Generate prediction by invoking the deployed endpoint\n",
    "datab= [\"2test hicham ici\"]\n",
    "preds = huggingface_pipeline_model.predict(data)\n",
    "\n",
    "#print predictions\n",
    "for pred in preds['prediction']:\n",
    "    print(pred['word'],pred['entity_group'], pred['score'], pred['start'], pred['end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c160447a-f046-488a-8d3f-ac2074a8a7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mon nom est Hicham, et pour l'anniversaire de 50ans et je vais payer avec une carte visa 4442223314488.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f742f5e-0aa6-48eb-bf83-580cb6376bee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data = b\"\\\\x80\\\\x05\\\\x95k\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8cgMon nom est Hicham, et pour l\\'anniversaire de 50ans et je vais payer avec une carte visa 4442223314488.\\\\x94.\"'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdata = \"data = b\\\"\\\\x80\\\\x05\\\\x95k\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8cgMon nom est Hicham, et pour l'anniversaire de 50ans et je vais payer avec une carte visa 4442223314488.\\\\x94.\\\"\"\n",
    "bdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e9fc09c-d3c8-4e28-b790-5c765de7fd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': [{'entity_group': 'FIRSTNAME',\n",
       "   'score': 0.4478805363178253,\n",
       "   'word': 'Hicham,',\n",
       "   'start': 12,\n",
       "   'end': 19},\n",
       "  {'entity_group': 'CREDITCARDNUMBER',\n",
       "   'score': 0.3592835068702698,\n",
       "   'word': '4442223314488.',\n",
       "   'start': 89,\n",
       "   'end': 103}]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The OCI SDK must be installed for this example to function properly.\n",
    "# Installation instructions can be found here: https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/pythonsdk.htm\n",
    "\n",
    "import requests\n",
    "import oci\n",
    "from oci.signer import Signer\n",
    "\n",
    "config = oci.config.from_file(\"~/.oci/config\") # replace with the location of your oci config file\n",
    "auth = Signer(\n",
    "  tenancy=config['tenancy'],\n",
    "  user=config['user'],\n",
    "  fingerprint=config['fingerprint'],\n",
    "  private_key_file_location=config['key_file'],\n",
    "  pass_phrase=config['pass_phrase'])\n",
    "\n",
    "endpoint = 'https://modeldeployment.ca-toronto-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.ca-toronto-1.amaaaaaa3hvgr2qazlfu5f5vwmt7k7j5bp3bpn7la73tnvqrca36ibtcmhla/predict'\n",
    "body = {\"inputs\":data} # payload goes here\n",
    "headers = {} # header goes here\n",
    "\n",
    "requests.post(endpoint, json=body, auth=auth, headers=headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d70497-7570-4017-bd82-d32f57455045",
   "metadata": {},
   "source": [
    "#### To do:\n",
    "1- None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch21_p39_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch21_p39_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
